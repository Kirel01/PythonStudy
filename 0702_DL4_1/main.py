'''
    * Deep Learning으로 정교하게 예측하기
        1) 인공신경망
            - 다층 퍼셉트론(MLP)
                - 입력층, 출력층, 은닉층
            - 경사하강법
                - 오류역전파 (backpropagation)

        2) 신경망 구조
            - 입력층
            - 은닉층
                - ReLU 함수, 탄젠트 함수
            - 출력층
                - Softmax 분류기

        3) Deep Learning

'''

'''
    * 인공신경망 (ANN)
        - 다층 퍼셉트론(Multi-Layer Perceptron)
            - 입력층 하나와 은닉층(Hidden Layer)이라 불리는 하나 이상의 층과
              출력층으로 구성 
            - 출력층을 제외하고 모든 층은 편향 뉴런을 포함하여 다음충과 완전히 연결
            - 인공신경망의 은닉층이 2개 이상일때 심층 신경망(DNN)이라 부름  
        - 역전파 (Backpropagation)
            - 다층 퍼셉트론을 효율적으로 학습시킬 수 있는 알고리즘 
            - 각 훈련 샘플(데이터셋)에 대해 역전파 알고리즘이 먼저 예측을 만들고,
              오차를 측정하고(정방향), 그 다음 역방향으로 각 층을 거치면서
              각 연결이 오차에 기여한 정도를 측정(역방향)       
            - 이 오차가 감소하도록 가중치(weight)를 조금씩 조정 <== 경사하강법   
            
    * Activation Function
        - 활성화 함수
            - 딥러닝 네트워크에서는 노드에 들어오는 값들에 대해
              곧바로 다음 레이어로 전달하지 않고
              주로 비선형 함수를 통과시킨 후 전달함 
            - 이때 사용하는 함수를 활성화 함수라 부름.  
        - 은닉층
            - 하이퍼볼릭 탄젠트(tanh) 함수
                - 시그모이드(Sigmoid) 함수를 보완
                - 출력범위가 -1 ~ 1 사이 => 각층의 출력이 다소 정규화
                - 원점주위로 몰리는 경향이 있음 
            - ReLU 함수
                - 계산속도 빠름. 
                - 출력에 최댓값 없음                 
        - 출력층 
            - 소프트맥스 활성화 함수                                       
'''





















